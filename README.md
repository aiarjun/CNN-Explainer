# CNN-Explainer

This repository implements the following techniques for interpreting convolutional neural networks:

1. Saliency maps <sup>[1]</sup>
2. Guided Backpropagation <sup>[2]</sup>
3. Class visualization <sup>[3]</sup>
4. Grad-CAM <sup>[4]</sup>

Apart from this, the following techniques are also implemented

1. Adversarial fooling (by backpropagating classification error into the image) <sup>[5]</sup>

## References

1. 

2. 

3.

4.

5.
